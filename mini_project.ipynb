{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.8.0-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saadl\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\saadl\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\saadl\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\saadl\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saadl\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\saadl\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Downloading pymongo-4.8.0-cp312-cp312-win_amd64.whl (680 kB)\n",
      "   ---------------------------------------- 0.0/680.4 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/680.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 41.0/680.4 kB 495.5 kB/s eta 0:00:02\n",
      "   ----- --------------------------------- 92.2/680.4 kB 871.5 kB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 174.1/680.4 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 307.2/680.4 kB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 501.8/680.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 680.4/680.4 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 307.7/307.7 kB 19.8 MB/s eta 0:00:00\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.6.1 pymongo-4.8.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pymongo scikit-learn python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as mp\n",
    "from tensorflow.keras import layers\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import models\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect with MongoDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_CONNECTION_STRING = ''\n",
    "clint = MongoClient(MONGO_CONNECTION_STRING)\n",
    "db = clint['traffic sign']\n",
    "train_collection = db['train_collection']\n",
    "validation_collection = db['validation_collection']\n",
    "\n",
    "data = list(collection.find())\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.drop('_id', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3465 images belonging to 2 classes.\n",
      "Found 866 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "data = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_image = data.flow_from_directory(\n",
    "    r'D:/T5/T5_Week4_MProj/traffic_sign_dataset/train',\n",
    "    #r'C:\\Users\\SaadL\\OneDrive\\المستندات\\for_VS\\T5_Week4_MProj\\traffic_sign_dataset\\train',\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_image = data.flow_from_directory(\n",
    "    r'D:/T5/T5_Week4_MProj/traffic_sign_dataset/train',\n",
    "    #r'C:\\Users\\SaadL\\OneDrive\\المستندات\\for_VS\\T5_Week4_MProj\\traffic_sign_dataset\\train',\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_generator_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range =0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearset'\n",
    ")\n",
    "aug_train_image = Data_generator_train.fit(train_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_model = models.Sequential([\n",
    "# Layer 1\n",
    "layers.Conv2D(64, (5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=(224, 224, 3)),\n",
    "layers.MaxPooling2D((2, 2)),\n",
    "layers.BatchNormalization(),\n",
    "layers.Conv2D(128, (5, 5), strides=(1, 1), padding='same', activation='relu'),\n",
    "layers.MaxPooling2D((2, 2)),\n",
    "layers.Dropout((0.3)),\n",
    "layers.Conv2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu'),\n",
    "layers.BatchNormalization(),\n",
    "# Layer 2\n",
    "layers.Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "layers.MaxPooling2D((2, 2)),\n",
    "layers.BatchNormalization(),\n",
    "layers.Dropout((0.3)),\n",
    "layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "layers.MaxPooling2D((2, 2)),\n",
    "layers.BatchNormalization(),\n",
    "# Layer 3\n",
    "layers.Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "layers.MaxPooling2D((2, 2)),\n",
    "layers.BatchNormalization(),\n",
    "layers.Dropout((0.3)),\n",
    "layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "layers.MaxPooling2D((2, 2)),\n",
    "layers.BatchNormalization(),\n",
    "# Layer 4\n",
    "layers.Flatten(),\n",
    "layers.Dense(units=256, activation='relu'),\n",
    "layers.Dropout((0.3)),\n",
    "layers.Dense(units=15, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the traffic_model + summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "traffic_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the traffic_model with the training and validating the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_history = traffic_model.fit(aug_x_train, batch_size=400, epochs=100, validation_data=(aug_x_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_model.evaluate(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
